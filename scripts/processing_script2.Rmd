---
title: 'Negation Production Processing Script: Study 2'
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Documents/LDS/Production_Study/negation_production")
library(tidyverse)
library(magrittr)
library(feather)
library(binom)
library(childesr)
library(lubridate)
library(tm)
library(knitr)
library(kableExtra)
library(reshape)
library(reshape2)
library(RColorBrewer)
```


```{r, include= FALSE}

# english_negation <- get_utterances(language = "eng", age = c(0,24), role = "Target_Child")
# write.csv(english_negation, file="raw_data/eng_utterances_undertwo.csv")
# all_utterances <- english_negation
# 
# 
# count_types <- function(string){
#  n <- nlevels(as.factor(unlist(strsplit(string, " "))))
#  return(n)
# }
# 
# count_tokens <- function(string){
#  n <- unlist(strsplit(string, " "))
#  return(length(n))
# }
# 
# english_negation <-
#  all_utterances %>%
#  mutate(clean_utterances = removeWords(gloss, c("xxx ?", "yyy ?", "um ?", "uh ?", "ah ?"))) %>%
#  filter(grepl('( |^)no( |$)|( |^)not( |$)|( |^)[a-z]+n\'t( |$)', clean_utterances)) %>%
#  filter(!grepl('not yet transcribed need to fix', gloss)) %>%
#  filter(!grepl('^ ?$', part_of_speech)) %>%
#  mutate(can = grepl('^can | can | can$|cannot|can\'t', clean_utterances)) %>%
#  mutate(do = grepl('^do | do | do$|don\'t|does|doesn\'t', clean_utterances)) %>%
#  mutate(want = grepl('^want | want | want$', clean_utterances))%>%
#  mutate(n_types_clean = unlist(lapply(clean_utterances, count_types))) %>%
#  mutate(n_tokens_clean = unlist(lapply(clean_utterances, count_tokens))) %>%
#  mutate(type_token_ratio = n_types_clean/n_tokens_clean)
# 
# 
# write.csv(english_negation, file="raw_data/eng_negation_undertwo.csv")
```

```{r cleanup, include=FALSE}
undertwo_neg <- read.csv("raw_data/eng_negation_undertwo.csv")

# Modifications to part_of_speech column
condense_pos <- function (gloss, pos) 
{
  # Replace POS with 'no' where relevant
  if (pos == "") {return(pos)}
  no_list = list()
  gloss_list = strsplit(gloss," ")
  for (g in 1:length(gloss_list[[1]])) {
    if (gloss_list[[1]][g] == "no"){
      no_list <- append(unlist(no_list), g)
    }
  }
  pos_list <- unlist(strsplit(pos, " "))
  pos_list[unlist(no_list)] <- "no"
  result <- removeWords(paste(pos_list, collapse = " "), "NA")
  
  # Condense POS to major categories
  result <- result %>%
    str_replace_all('pro:\\w*|n:prop', 'n') %>% 
    str_replace_all('neg', 'not') %>% 
    str_replace_all('adv:\\w*', 'adv') %>% 
    str_replace_all('det:\\w*', 'det')
  
  
  # Condense repeated 'no'
  result <- gsub(' (no )+', ' no ', result) 
  result <- gsub(' (no ?)+$', ' no', result)
  result <- gsub('^(no )+', 'no ', result)
  result <- gsub('^(no ?)+$', 'no', result)
  
  return (result)
}


undertwo_neg$clean_utterances <- as.character(undertwo_neg$clean_utterances)
undertwo_neg$part_of_speech <- as.character(undertwo_neg$part_of_speech)

# Add condensed part of speech column to reflect simplifications
undertwo_neg <- undertwo_neg %>%
  mutate(condensed_p_o_s = mapply(condense_pos, clean_utterances, part_of_speech)) %>%
  # remove single-word negations
  filter(!grepl('^no$|^not$|^[a-z]*n\'t$', condensed_p_o_s))

# Fix miscodes
replacements <- 
  list(
    # Nouns coded incorrectly
    list("n no", "horsie no"), 
    list("not n", "not baby", "not lunch", "not diaper", "not blanket"),
    list("n mod v n", "I canâ€™t go living+room"), 
    # Verbs coded incorrectly
    list("no v", "no tickle", "no bite", "no push", "no works", "no hold", "no play", "no touch", "no look", "no help", "no see"),
    list("no v n", "no like sweet+corn", "no touch Lastname",
         "no pop weasel", "no hold it", "no hug baby", "no brush hair", "no pinch that","no ride horsie", "no stop it",
         "no help me", "no spin it", "no play toys"), 
    list("no n v", "no Mommy Humm", "no mummy sneeze", "no everybody fall", "no hair wash"), 
    list("no n n v", "no Mommy baby seep"),
    list("no n v n", "no Abi play toys", "no everybody play toys", "no mummy check nappie", "no Papa tie it"),
    list("no v n n", "no hold daddy hand", "no dump Baura puzzle", "no spin it mom", "no pinch that monkey"), 
    list("n no v n", "man no taste it"),
    # Miscodes due to stem skipping repeated words
    list("no v n", "no no like Winnie+Pooh"),
    list("no", "no"), 
    list("no v n", "no want din+dins", "no go bathroom"),
    list("no n prep n", "no no piece a paper")
  )


# Insert replacements
fix <- function(df, replacements) 
{
  for (i in 1:length(replacements))
  {
    for (j in 2:length(replacements[[i]]))
    {
      df$condensed_p_o_s[df$clean_utterances == replacements[[i]][[j]]] <- replacements[[i]][[1]]
    }
  }
  return(df)
}

undertwo_neg <- fix(undertwo_neg, replacements)

constructions <- plyr::count(undertwo_neg$condensed_p_o_s) %>%
  arrange(desc(freq))

filtered_constructions <- constructions %>%
  filter(freq>10, x!="")

```

Total # of utterances: `r nrow(undertwo_neg)`

|Abbreviation     | Meaning       |
|-----------------|---------------|
| adj             | adjective     |
| adv             | adverb        |
| co              | ???           |
| det             | determiner    |
| mod             | modal         | 
| n               | noun (includes pronouns and proper nouns) |
| part            | participle    |
| prep            | preposition   |
| qn              | quantifier    |
| v               | verb          |


``` {r, echo=FALSE}
table1 <- data.frame(
  "Construction" = c( "no n" ,  "co no" , "mod v n" , "n mod v n" , "n mod v" , "mod v", "n mod", "no qn n" , "no v" , "no n n", "no v n" , "not n",
                      "no n v n" , "not adv" ,"no adv" , "n no" , "no co" , "mod v n n",  "no n v", "no prep n" , "not adj", "n mod v prep" , "n v no" ,  "mod n" ,
                      "n no v n" ,  "not det n" , "not v n" ,  "no det n" ,  "mod v adv" ,  "no n adv" , "n no n" , "n not n"  , "no adj" ,  "no part" ), 
  "Examples" = c("no baby, no horsie, no juice", 
                 "oh no, okay no, yeah no", 
                 "don't touch that, don't fit car, can't open it", 
                 "I don't want juice, I can't find duck, cow won't go Mama", 
                 "I don't know, they don't fit, I can't open", 
                 "don't go, doesn't work, can't catch", 
                 "I can't, Jane doesn't, mine didn't", 
                 "no more stuff, no other pennies, no like doggy", 
                 "no read, no pooped, no want", 
                 "no baby bubble, no this one, no you pencil", 
                 "no sit chair, no have cracker, no eat milk", 
                 "not noodle, not home, not Toffer's", 
                 "no car go car, no comb want brush, no mummy do it", 
                 "not today, not there, not yet", 
                 "no there, no up, no behind", 
                 "mammy no, apple no, train no", 
                 "no no, no yes, no thanks", 
                 "don't eat skin part, don't touch that book, can't find bunny rabit", 
                 "no mail came, no mummy go, no I wanted", 
                 "no in tree, no with this, no like bubbles", 
                 "not good, not dirty, not real", 
                 "I don't want to, Laura don't want to", 
                  "doll sit no, I take no, Joana say no", 
                 "can't tea, don't Mommy, didn't I", 
                  "man no taste it, I no do it", 
                 "not my car, not a cat, not a white", 
                 "not eat rocks, not have coffee, not green one", 
                 "no my turn, no a cow, no the hammer", 
                 "can't come in, don't fall down, doesn't fit here", 
                 "no jacket on, no monkey there, no lie down", 
                 "straws no straws, Mommie no mail, there's no towel", 
                 "pizza not pizza, pizza not apples, that not knees", 
                 "no happy, no pretend, no brown", 
                 "no bouncing, no eating, no hurting")
)

freq <- function(pos) 
{
  filter(undertwo_neg, condensed_p_o_s == pos)$clean_utterances %>% length()
}

table1 <- table1 %>%
  mutate(Frequency = sapply(Construction, freq))

table1 <- table1[order(-table1$Frequency),]

kable(table1[,c(1, 3, 2)]) %>%
  kable_styling(font_size = 12) %>%
  column_spec(4, width = "20em")

table2 <- data.frame("Category" = c("Can", "Want", "Do","Don't", "Don't want", "Don't know", "Don't like", "No _", "No more", "Not _", "Presentential \`No\'", "Pre-VP \`No\'", "Sentence-internal \`No\'", "Presentential \`Not\'", "Pre-VP \`Not\'", "Sentence-internal \'Not\'"), 
                     "Frequency" = c(length(filter(undertwo_neg, can)$clean_utterances), 
                                     length(filter(undertwo_neg, want)$clean_utterances),
                                     length(filter(undertwo_neg, do)$clean_utterances), 
                                     filter(undertwo_neg, grepl('don\'t', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('don\'t want', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('don\'t know', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('don\'t like', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^no [a-z]+$', condensed_p_o_s) & condensed_p_o_s != "no no")$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('( |^)no more( |$)', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^not [a-z]+$', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^no n v ?.*', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^no v ?.*', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^n no v ?.*', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^not n v ?.*', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^not v ?.*', condensed_p_o_s))$clean_utterances %>% length(), 
                                     filter(undertwo_neg, grepl('^n not v ?.*', condensed_p_o_s))$clean_utterances %>% length()), 
                     "Examples" = c("I can't find a blankie, can't eat, no no I can not do", 
                                    "Don't want to, no comb want brush, no want the baby",
                                    "don't like it, I don't feel good, no do it Mummy", 
                                    "don't like it, no don't, I don't know",
                                    "I don't want juice, don't want it, Laura don't want to",
                                    "I don't know, I don't know name of them, you don't know how zip zip up",
                                    "I don't like it, don't like toast, I don't like",
                                    "no go, no stupid, no now, no baby",
                                    "no more, no more corn, there's no more time",
                                    "not bad, not write, not quite",
                                    "no Mommy read, no baby bite me, no you wait there for me", 
                                    "no have black, no give me that, no bite",
                                    "man no taste it, I no eat",
                                    "not Fraser read it, not that keys",
                                    "Not shush, not write this book, not eat rocks",
                                    "cat not mother, that not fit, I not like it too"))

kable(table2, "latex") %>%
  kable_styling(font_size = 12) %>%
  #pack_rows("Don't", 4, 6); makes a header for rows 4-6
  add_indent(c(4, 5, 6, 7)) %>%
  row_spec(3, bold = T) %>%
  column_spec(3, width = "20em")

```


``` {r, include=FALSE}
#filters for 'no [anything], excluding repeated 'no'; 1183 utterances (33.8%)
filter(undertwo_neg, grepl('^no .*', condensed_p_o_s) & !grepl('^(no ?)+$', condensed_p_o_s))$clean_utterances %>% length()

#filters for 'no n [anything]', excluding repeated 'no'; 236 utterances (6.75%)
filter(undertwo_neg, grepl('^no n.*', condensed_p_o_s) & !grepl('^(no ?)+$', condensed_p_o_s))$clean_utterances %>% length()

# filters for 'do not'; 22 utterances (!!!!) vs. 602 'don't' utterances
filter(undertwo_neg, grepl('( |^)do not( |$)', clean_utterances))$clean_utterances
# Same with 'can not'; 2 utterances vs 208 'can't' utterances


```


```{r utterance breakdown, echo=FALSE}

# Bin utterances by month

tags <- c("0-1", "1-2", "2-3", "3-4", "4-5", "5-6", "6-7", "7-8", "8-9", "9-10", "10-11", "11-12", "12-13", "13-14", "14-15", "15-16", "16-17", "17-18", "18-19", "19-20", "20-21", "21-22", "22-23", "23-24")

undertwo_neg <- undertwo_neg %>% 
  mutate(bin = case_when(
    target_child_age < 1 ~ tags[1],
    target_child_age >= 1 & target_child_age < 2 ~ tags[2],
    target_child_age >= 2 & target_child_age < 3 ~ tags[3],
    target_child_age >= 3 & target_child_age < 4 ~ tags[4],
    target_child_age >= 4 & target_child_age < 5 ~ tags[5],
    target_child_age >= 5 & target_child_age < 6 ~ tags[6],
    target_child_age >= 6 & target_child_age < 7 ~ tags[7],
    target_child_age >= 7 & target_child_age < 8 ~ tags[8],
    target_child_age >= 8 & target_child_age < 9 ~ tags[9],
    target_child_age >= 9 & target_child_age < 10 ~ tags[10],
    target_child_age >= 10 & target_child_age < 11 ~ tags[11],
    target_child_age >= 11 & target_child_age < 12 ~ tags[12],
    target_child_age >= 12 & target_child_age < 13 ~ tags[13],
    target_child_age >= 13 & target_child_age < 14 ~ tags[14],
    target_child_age >= 14 & target_child_age < 15 ~ tags[15],
    target_child_age >= 15 & target_child_age < 16 ~ tags[16],
    target_child_age >= 16 & target_child_age < 17 ~ tags[17],
    target_child_age >= 17 & target_child_age < 18 ~ tags[18],
    target_child_age >= 18 & target_child_age < 19 ~ tags[19],
    target_child_age >= 19 & target_child_age < 20 ~ tags[20],
    target_child_age >= 20 & target_child_age < 21 ~ tags[21],
    target_child_age >= 21 & target_child_age < 22 ~ tags[22],
    target_child_age >= 22 & target_child_age < 23 ~ tags[23],
    target_child_age >= 23 & target_child_age < 24 ~ tags[24]
    ))

# Tag negation type 
neg_tag <- function(arg) 
{
  if(arg == ""){return("other")}
  neg_list = list()
  word_list = strsplit(arg, " ")[[1]]
  for (w in 1:length(word_list)) 
  {
    word = word_list[[w]]
    if (word == "no" | word == "not" | word == "mod")
    {
      neg_list <- append(unlist(neg_list), word)
    }
  }
  if (length(neg_list) == 0) {return("other")}
  return(paste(unique(neg_list), collapse = "_"))
}
 
undertwo_neg <- undertwo_neg %>%
  mutate(negation_type = unlist(lapply(condensed_p_o_s, neg_tag)))


type_counts <- undertwo_neg %>%
  filter(!grepl("^no$", condensed_p_o_s)) %>% 
  filter(!grepl("^[a-z]*n\'t$", condensed_p_o_s)) %>% 
  filter(!grepl("^not$", condensed_p_o_s)) %>% 
  count(bin, negation_type)

ggplot(type_counts %>% within(negation_type[n < 10] <- 'other' )) +
  geom_bar(aes(bin, n, fill = negation_type), stat = "identity") +
  xlab("Age Bin") +
  ylab("Utterance Count") +
  labs(fill = "Negation Type", title = "All Multi-word Negative Utterances") +
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5))

bin_counts <- tally(group_by(type_counts, bin), n)

type_proportions <- dcast(type_counts, bin~negation_type, sum, value.var = "n") %>%
  mutate(
    mod = mod/bin_counts$n,
    mod_no = mod_no/bin_counts$n,
    mod_not = mod_not/bin_counts$n,
    no = no/bin_counts$n,
    no_mod = no_mod/bin_counts$n,
    not = not/bin_counts$n,
    other = other/bin_counts$n,
    no_not = no_not/bin_counts$n,
    no_mod_not = no_mod_not/bin_counts$n,
    not_mod = not_mod/bin_counts$n,
    not_no = not_no/bin_counts$n
  ) %>%
  melt(id.vars = "bin", value.name = "n", variable.name = "negation_type")

ggplot(type_proportions %>%  within(negation_type[n < .01] <- 'other' )) +
  geom_bar(aes(bin, n, fill = negation_type), stat = "identity") +
  xlab("Age Bin") +
  ylab("Proportion of Utterances") +
  labs(fill = "Negation Type", title = "All Multi-word Negative Utterances") +
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5))
```

```{r no analysis, echo=FALSE}
# No composition

nos <- undertwo_neg %>%
  filter(grepl('(^| )no ', condensed_p_o_s)) %>%
  mutate(noN = str_count(condensed_p_o_s, '( |^)no n')) %>%
  #mutate(noNP = str_count(condensed_p_o_s, '( |^)no( det)? n')) %>%
  mutate(noV = str_count(condensed_p_o_s, '( |^)no v')) %>%
  mutate(noADV = str_count(condensed_p_o_s, '( |^)no adv')) %>%
  mutate(noADJ = str_count(condensed_p_o_s, '( |^)no adj'))%>%
  mutate(noCO = str_count(condensed_p_o_s, '( |^)no co'))%>%
  mutate(noUNI = str_count(condensed_p_o_s, '( |^)no uni'))%>%
  mutate(noPART = str_count(condensed_p_o_s, '( |^)no part'))%>%
  mutate(noQN = str_count(condensed_p_o_s, '( |^)no qn'))%>%
  mutate(noMOD = str_count(condensed_p_o_s, '( |^)no mod'))%>%
  mutate(noPREP = str_count(condensed_p_o_s, '( |^)no prep'))%>%
  mutate(noON = str_count(condensed_p_o_s, '( |^)no on'))%>%
  mutate(noDET = str_count(condensed_p_o_s, '( |^)no det')) %>%
  mutate(sum = noN + noV + noADV + noADJ + noCO + noUNI + noPART + noQN + noMOD + noPREP + noON + noDET)


# Utterance count by composition of no
no_sums <- data.frame("Bin" = unique(nos$bin)) %>%
  # Count the number of times 'no' is uttered in each bin
  mutate(No_Count = tally(group_by(nos, bin), sum)$n) %>%
  # Calculate the proportion of 'no' utterances followed by each POS in each bin
  mutate(noun = tally(group_by(nos, bin), noN)$n) %>%
  mutate(verb = tally(group_by(nos, bin), noV)$n)%>%
  mutate(adverb = tally(group_by(nos, bin), noADV)$n) %>%
  mutate(adjective = tally(group_by(nos, bin), noADJ)$n)%>%
  mutate(co = tally(group_by(nos, bin), noCO)$n)%>%
  mutate(uni = tally(group_by(nos, bin), noUNI)$n)%>%
  mutate(participle = tally(group_by(nos, bin), noPART)$n)%>%
  mutate(quantifier = tally(group_by(nos, bin), noQN)$n)%>%
  mutate(modal = tally(group_by(nos, bin), noMOD)$n)%>%
  mutate(preposition = tally(group_by(nos, bin), noPREP)$n)%>%
  mutate(onomatopoeia = tally(group_by(nos, bin), noON)$n)%>%
  mutate(determiner = tally(group_by(nos, bin), noDET)$n)

# Calculate proportions of total no utterances for each pos in each bin
no_proportions <- (no_sums[,3:14] / no_sums[,2]) %>%
  mutate(Bin = no_sums$Bin)

# Consolidate dataframes for graphing
no_sums_melted <- no_sums%>%subset(select = -No_Count) %>%melt(id.vars = "Bin")
no_proportions_melted <- melt(no_proportions,id.vars = "Bin")

# Stacked bar graph of 'no' composition
# By proportion of no utterances
ggplot(filter(no_proportions_melted, value > .0)) +
  geom_bar(stat = "identity", aes(Bin, value, fill = variable ))+
  ylim(0, 1) +
  xlab("Age Bin")+
  ylab("Proportion of Instances")+
  ggtitle("\'No\' Composition")+
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5))

# By total count
ggplot(no_sums_melted) +
  geom_bar(stat = "identity", aes(Bin, value, fill = variable ))+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("\'No\' Composition")+
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5))

```

```{r Not Composition, echo=FALSE}
# Not Composition
nots <- undertwo_neg %>%
  filter(grepl('(^| )not ', condensed_p_o_s)) %>%
  mutate(notN = str_count(condensed_p_o_s, '( |^)not n')) %>%
  #mutate(notNP = str_count(condensed_p_o_s, '( |^)not( det)? n')) %>%
  mutate(notV = str_count(condensed_p_o_s, '( |^)not v')) %>%
  mutate(notADV = str_count(condensed_p_o_s, '( |^)not adv')) %>%
  mutate(notADJ = str_count(condensed_p_o_s, '( |^)not adj'))%>%
  mutate(notCO = str_count(condensed_p_o_s, '( |^)not co'))%>%
  mutate(notUNI = str_count(condensed_p_o_s, '( |^)not uni'))%>%
  mutate(notPART = str_count(condensed_p_o_s, '( |^)not part'))%>%
  mutate(notQN = str_count(condensed_p_o_s, '( |^)not qn'))%>%
  mutate(notMOD = str_count(condensed_p_o_s, '( |^)not mod'))%>%
  mutate(notPREP = str_count(condensed_p_o_s, '( |^)not prep'))%>%
  mutate(notON = str_count(condensed_p_o_s, '( |^)not on'))%>%
  mutate(notDET = str_count(condensed_p_o_s, '( |^)not det')) %>%
  mutate(notINF = str_count(condensed_p_o_s, '( |^)not inf')) %>%
  mutate(sum = notN + notV + notADV + notADJ + notCO + notUNI + notPART + notQN + notMOD + notPREP + notON + notDET + notINF)

# Check for missing parts of speech; right notw contains unk, chi, and bab
leftovers <- nots %>%
  filter(sum == 2)

# Utterance count by composition of not
not_sums <- data.frame("Bin" = unique(nots$bin)) %>%
  # Count the number of times 'not' is uttered in each bin
  mutate(not_Count = tally(group_by(nots, bin), sum)$n) %>%
  # Calculate the proportion of 'not' utterances followed by each POS in each bin
  mutate(noun = tally(group_by(nots, bin), notN)$n) %>%
  mutate(verb = tally(group_by(nots, bin), notV)$n)%>%
  mutate(adverb = tally(group_by(nots, bin), notADV)$n) %>%
  mutate(adjective = tally(group_by(nots, bin), notADJ)$n)%>%
  mutate(co = tally(group_by(nots, bin), notCO)$n)%>%
  mutate(uni = tally(group_by(nots, bin), notUNI)$n)%>%
  mutate(participle = tally(group_by(nots, bin), notPART)$n)%>%
  mutate(quantifier = tally(group_by(nots, bin), notQN)$n)%>%
  mutate(modal = tally(group_by(nots, bin), notMOD)$n)%>%
  mutate(preposition = tally(group_by(nots, bin), notPREP)$n)%>%
  mutate(onotmatopoeia = tally(group_by(nots, bin), notON)$n)%>%
  mutate(determiner = tally(group_by(nots, bin), notDET)$n) 
  #mutate(infinitive = tally(group_by(nots, bin), notINF)$n)

# Calculate proportions of total not utterances for each pos in each bin
not_proportions <- (not_sums[,3:14] / not_sums[,2]) %>%
  mutate(Bin = not_sums$Bin)

# Consolidate dataframes for graphing
not_sums_melted <- not_sums%>%subset(select = -not_Count) %>%melt(id.vars = "Bin")
not_proportions_melted <- melt(not_proportions,id.vars = "Bin")

# Stacked bar graph of 'not' composition

# By proportion of not utterances
suppressWarnings(
ggplot(filter(not_proportions_melted, value > .0)) +
  geom_bar(stat = "identity", aes(Bin, value, fill = variable ))+
  ylim(0, 1) +
  xlab("Age Bin")+
  ylab("Proportion of Instances")+
  ggtitle("\'Not\' Composition")+
  #scale_fill_brewer(palette=getPalette())+
  scale_fill_brewer(palette="Paired")+
  #scale_fill_manual(values=as.vector(alphabet2()))+
  theme(plot.title = element_text(hjust = 0.5))
)
# By total count
suppressWarnings(
ggplot(not_sums_melted) +
  geom_bar(stat = "identity", aes(Bin, value, fill = variable ))+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("\'Not\' Composition")+
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5))
)
```

```{r mod Composition, echo=FALSE}
# mod Composition
mods <- undertwo_neg %>%
  filter(grepl('(^| )mod ', condensed_p_o_s)) %>%
  mutate(modN = str_count(condensed_p_o_s, '( |^)mod n')) %>%
  #mutate(modNP = str_count(condensed_p_o_s, '( |^)mod( det)? n')) %>%
  mutate(modV = str_count(condensed_p_o_s, '( |^)mod v')) %>%
  mutate(modADV = str_count(condensed_p_o_s, '( |^)mod adv')) %>%
  mutate(modADJ = str_count(condensed_p_o_s, '( |^)mod adj'))%>%
  mutate(modCO = str_count(condensed_p_o_s, '( |^)mod co'))%>%
  mutate(modUNI = str_count(condensed_p_o_s, '( |^)mod uni'))%>%
  mutate(modPART = str_count(condensed_p_o_s, '( |^)mod part'))%>%
  mutate(modQN = str_count(condensed_p_o_s, '( |^)mod qn'))%>%
  mutate(modMOD = str_count(condensed_p_o_s, '( |^)mod mod'))%>%
  mutate(modPREP = str_count(condensed_p_o_s, '( |^)mod prep'))%>%
  mutate(modON = str_count(condensed_p_o_s, '( |^)mod on'))%>%
  mutate(modDET = str_count(condensed_p_o_s, '( |^)mod det')) %>%
  mutate(modINF = str_count(condensed_p_o_s, '( |^)mod inf')) %>%
  mutate(sum = modN + modV + modADV + modADJ + modCO + modUNI + modPART + modQN + modMOD + modPREP + modON + modDET + modINF)

# Check for missing parts of speech; right modw contains unk, chi, and bab
leftovers <- mods %>%
  filter(sum == 0)

# Utterance count by composition of mod
mod_sums <- data.frame("Bin" = unique(mods$bin)) %>%
  # Count the number of times 'mod' is uttered in each bin
  mutate(mod_Count = tally(group_by(mods, bin), sum)$n) %>%
  # Calculate the proportion of 'mod' utterances followed by each POS in each bin
  mutate(noun = tally(group_by(mods, bin), modN)$n) %>%
  mutate(verb = tally(group_by(mods, bin), modV)$n)%>%
  mutate(adverb = tally(group_by(mods, bin), modADV)$n) %>%
  mutate(adjective = tally(group_by(mods, bin), modADJ)$n)%>%
  mutate(co = tally(group_by(mods, bin), modCO)$n)%>%
  mutate(uni = tally(group_by(mods, bin), modUNI)$n)%>%
  mutate(participle = tally(group_by(mods, bin), modPART)$n)%>%
  mutate(quantifier = tally(group_by(mods, bin), modQN)$n)%>%
  mutate(modal = tally(group_by(mods, bin), modMOD)$n)%>%
  mutate(preposition = tally(group_by(mods, bin), modPREP)$n)%>%
  mutate(omodmatopoeia = tally(group_by(mods, bin), modON)$n)%>%
  mutate(determiner = tally(group_by(mods, bin), modDET)$n)

# Calculate proportions of total mod utterances for each pos in each bin
mod_proportions <- (mod_sums[,3:14] / mod_sums[,2]) %>%
  mutate(Bin = mod_sums$Bin)

# Consolidate dataframes for graphing
mod_sums_melted <- mod_sums%>%subset(select = -mod_Count) %>%melt(id.vars = "Bin")
mod_proportions_melted <- melt(mod_proportions,id.vars = "Bin")

# Stacked bar graph of 'mod' composition
# By proportion of mod utterances
ggplot(filter(mod_proportions_melted, value > .0)) +
  geom_bar(stat = "identity", aes(Bin, value, fill = variable ))+
  ylim(0, 1) +
  xlab("Age Bin")+
  ylab("Proportion of Instances")+
  ggtitle("\'mod\' Composition")+
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5))

# By total count
ggplot(mod_sums_melted) +
  geom_bar(stat = "identity", aes(Bin, value, fill = variable ))+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("\'mod\' Composition")+
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5))
```


```{r nt Composition, echo=FALSE}

# Finds successor of n't word; doesn't handle cases where there are multiple
nt_successor <- function(gloss, pos)
{
  gloss_list = strsplit(gloss, " ")
  pos_list <- unlist(strsplit(pos, " "))
  #nt_list = list()
  nt = 0
  for (g in 1:length(gloss_list[[1]])) {
    if (grepl('[a-z]+n\'t', gloss_list[[1]][g])){
      return(pos_list[g+1])
    }
  }
}

nt_successor("hello amn't dog", "co aux n")


### NONE OF THE BELOW IS CORRECT ITS JUST COPIED FROM MOD ###

# nt Composition
nts <- undertwo_neg %>%
  filter(grepl('(^| )[a-z]+n\'t ', condensed_p_o_s)) %>%
  mutate(ntN = str_count(condensed_p_o_s, '( |^)mod n')) %>%
  #mutate(modNP = str_count(condensed_p_o_s, '( |^)mod( det)? n')) %>%
  mutate(modV = str_count(condensed_p_o_s, '( |^)mod v')) %>%
  mutate(modADV = str_count(condensed_p_o_s, '( |^)mod adv')) %>%
  mutate(modADJ = str_count(condensed_p_o_s, '( |^)mod adj'))%>%
  mutate(modCO = str_count(condensed_p_o_s, '( |^)mod co'))%>%
  mutate(modUNI = str_count(condensed_p_o_s, '( |^)mod uni'))%>%
  mutate(modPART = str_count(condensed_p_o_s, '( |^)mod part'))%>%
  mutate(modQN = str_count(condensed_p_o_s, '( |^)mod qn'))%>%
  mutate(modMOD = str_count(condensed_p_o_s, '( |^)mod mod'))%>%
  mutate(modPREP = str_count(condensed_p_o_s, '( |^)mod prep'))%>%
  mutate(modON = str_count(condensed_p_o_s, '( |^)mod on'))%>%
  mutate(modDET = str_count(condensed_p_o_s, '( |^)mod det')) %>%
  mutate(modINF = str_count(condensed_p_o_s, '( |^)mod inf')) %>%
  mutate(sum = modN + modV + modADV + modADJ + modCO + modUNI + modPART + modQN + modMOD + modPREP + modON + modDET + modINF)

# Check for missing parts of speech; right modw contains unk, chi, and bab
leftovers <- mods %>%
  filter(sum == 0)

# Utterance count by composition of mod
mod_sums <- data.frame("Bin" = unique(mods$bin)) %>%
  # Count the number of times 'mod' is uttered in each bin
  mutate(mod_Count = tally(group_by(mods, bin), sum)$n) %>%
  # Calculate the proportion of 'mod' utterances followed by each POS in each bin
  mutate(noun = tally(group_by(mods, bin), modN)$n) %>%
  mutate(verb = tally(group_by(mods, bin), modV)$n)%>%
  mutate(adverb = tally(group_by(mods, bin), modADV)$n) %>%
  mutate(adjective = tally(group_by(mods, bin), modADJ)$n)%>%
  mutate(co = tally(group_by(mods, bin), modCO)$n)%>%
  mutate(uni = tally(group_by(mods, bin), modUNI)$n)%>%
  mutate(participle = tally(group_by(mods, bin), modPART)$n)%>%
  mutate(quantifier = tally(group_by(mods, bin), modQN)$n)%>%
  mutate(modal = tally(group_by(mods, bin), modMOD)$n)%>%
  mutate(preposition = tally(group_by(mods, bin), modPREP)$n)%>%
  mutate(omodmatopoeia = tally(group_by(mods, bin), modON)$n)%>%
  mutate(determiner = tally(group_by(mods, bin), modDET)$n)

# Calculate proportions of total mod utterances for each pos in each bin
mod_proportions <- (mod_sums[,3:14] / mod_sums[,2]) %>%
  mutate(Bin = mod_sums$Bin)

# Consolidate dataframes for graphing
mod_sums_melted <- mod_sums%>%subset(select = -mod_Count) %>%melt(id.vars = "Bin")
mod_proportions_melted <- melt(mod_proportions,id.vars = "Bin")

# Stacked bar graph of 'mod' composition
# By proportion of mod utterances
ggplot(filter(mod_proportions_melted, value > .0)) +
  geom_bar(stat = "identity", aes(Bin, value, fill = variable ))+
  ylim(0, 1) +
  xlab("Age Bin")+
  ylab("Proportion of Instances")+
  ggtitle("\'mod\' Composition")+
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5))

# By total count
ggplot(mod_sums_melted) +
  geom_bar(stat = "identity", aes(Bin, value, fill = variable ))+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("\'mod\' Composition")+
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5))
```


```{r Participants, echo=FALSE}
# Participant information

# 173
undertwo_neg$speaker_id %>% unique() %>% length()

speaker_counts <- undertwo_neg %>% count(speaker_id)

# Proportion of total (0, 24) utterances that include negation by age bin (maybe split bar graph?)
#all_utterances
# Proportion of children in each age bin producing negation
# Proportion of utterances that include negation by child (?)
```




