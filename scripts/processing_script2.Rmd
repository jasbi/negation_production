---
title: 'Negation Production Processing Script: Study 2'
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Documents/LDS/Production_Study/negation_production")
library(tidyverse)
library(magrittr)
library(feather)
library(binom)
library(childesr)
library(lubridate)
library(tm)
library(knitr)
library(kableExtra)
library(reshape)
library(reshape2)
library(RColorBrewer)
library(pals)
```


```{r, include= FALSE}
age_limits <- c(0, 48)
english_negation <- get_utterances(language = "eng", age = age_limits, role = "Target_Child")
write.csv(english_negation, file="raw_data/eng_utterances_undertwo.csv")
all_utterances <- english_negation


count_types <- function(string){
 n <- nlevels(as.factor(unlist(strsplit(string, " "))))
 return(n)
}

count_tokens <- function(string){
 n <- unlist(strsplit(string, " "))
 return(length(n))
}

english_negation <-
 all_utterances %>%
 mutate(clean_utterances = removeWords(gloss, c("xxx ?", "yyy ?", "um ?", "uh ?", "ah ?"))) %>%
 filter(grepl('( |^)no( |$)|( |^)not( |$)|( |^)[a-z]+n\'t( |$)', clean_utterances)) %>%
 filter(!grepl('not yet transcribed need to fix', gloss)) %>%
 filter(!grepl('^ ?$', part_of_speech)) %>%
 mutate(can = grepl('^can | can | can$|cannot|can\'t', clean_utterances)) %>%
  #gotta add did and didn't
 mutate(do = grepl('^do | do | do$|don\'t|does|doesn\'t', clean_utterances)) %>%
 mutate(want = grepl('^want | want | want$', clean_utterances))%>%
 mutate(n_types_clean = unlist(lapply(clean_utterances, count_types))) %>%
 mutate(n_tokens_clean = unlist(lapply(clean_utterances, count_tokens))) %>%
 mutate(type_token_ratio = n_types_clean/n_tokens_clean)


write.csv(english_negation, file="raw_data/eng_negation_undertwo.csv")
```

```{r cleanup, include=FALSE}
undertwo_neg <- read.csv("raw_data/eng_negation_undertwo.csv")

fix_nos <- function(x) 
{
  result <- gsub(' (no )+', ' no ', x) 
  result <- gsub(' (no ?)+$', ' no', result)
  result <- gsub('^ ?(no )+', 'no ', result)
  result <- gsub('^ ?(no ?)+$', 'no', result)
  return(result)
}

# Modifications to part_of_speech column
condense_pos <- function (gloss, pos) 
{
  # Replace POS with 'no' where relevant
  if (pos == "") {return(pos)}
  no_list = list()
  gloss_list = strsplit(gloss," ")
  for (g in 1:length(gloss_list[[1]])) {
    if (gloss_list[[1]][g] == "no"){
      no_list <- append(unlist(no_list), g)
    }
  }
  pos_list <- unlist(strsplit(pos, " "))
  pos_list[unlist(no_list)] <- "no"
  result <- removeWords(paste(pos_list, collapse = " "), "NA")
  
  # Condense POS to major categories
  result <- result %>%
    str_replace_all('pro:\\w*|n:\\w*', 'n') %>% 
    str_replace_all('neg', 'not') %>% 
    str_replace_all('adv:\\w*', 'adv') %>% 
    str_replace_all('det:\\w*', 'det') %>%
    str_replace_all('mod:\\w*', 'mod') 
  
  return (result)
}


undertwo_neg$clean_utterances <- as.character(undertwo_neg$clean_utterances)
undertwo_neg$part_of_speech <- as.character(undertwo_neg$part_of_speech)

# Add condensed part of speech column to reflect simplifications
undertwo_neg <- undertwo_neg %>%
  mutate(condensed_p_o_s = mapply(condense_pos, clean_utterances, part_of_speech)) %>%
  mutate(condensed_p_o_s = lapply(condensed_p_o_s, fix_nos)) %>%
  mutate(clean_utterances = lapply(clean_utterances, fix_nos)) %>%
  # remove single-word negations
  filter(!grepl('^no$|^not$|^[a-z]*n\'t$', condensed_p_o_s))

# Remove utterances that don't line up with their pos
check_lengths <- function(utterance, pos) 
{
  return(length(strsplit(utterance, " ")[[1]]) == length(strsplit(pos, " ")[[1]]))
}
undertwo_neg<- undertwo_neg %>%
  filter(mapply(check_lengths, condensed_p_o_s, clean_utterances))



# Fix miscodes
replacements <- 
  list(
    # Nouns coded incorrectly
    list("n no", "horsie no"), 
    list("not n", "not baby", "not lunch", "not diaper", "not blanket"),
    list("n mod v n", "I canâ€™t go living+room"), 
    # Verbs coded incorrectly
    list("no v", "no tickle", "no bite", "no push", "no works", "no hold", "no play", "no touch", "no look", "no help", "no see"),
    list("no v n", "no like sweet+corn", "no touch Lastname",
         "no pop weasel", "no hold it", "no hug baby", "no brush hair", "no pinch that","no ride horsie", "no stop it",
         "no help me", "no spin it", "no play toys"), 
    list("no n v", "no Mommy Humm", "no mummy sneeze", "no everybody fall", "no hair wash"), 
    list("no n n v", "no Mommy baby seep"),
    list("no n v n", "no Abi play toys", "no everybody play toys", "no mummy check nappie", "no Papa tie it"),
    list("no v n n", "no hold daddy hand", "no dump Baura puzzle", "no spin it mom", "no pinch that monkey"), 
    list("n no v n", "man no taste it")
    # Miscodes due to stem skipping repeated words
    # list("no v n", "no no like Winnie+Pooh"),
    # list("no", "no"), 
    # list("no v n", "no want din+dins", "no go bathroom"),
    # list("no n prep n", "no no piece a paper")
  )


# Insert replacements
fix <- function(df, replacements) 
{
  for (i in 1:length(replacements))
  {
    for (j in 2:length(replacements[[i]]))
    {
      df$condensed_p_o_s[df$clean_utterances == replacements[[i]][[j]]] <- replacements[[i]][[1]]
    }
  }
  return(df)
}

undertwo_neg <- fix(undertwo_neg, replacements)

constructions <- count(undertwo_neg$condensed_p_o_s) %>%
  arrange(desc(freq))

filtered_constructions <- constructions %>%
  filter(freq>10, x!="")

```

Total # of utterances: `r nrow(undertwo_neg)`

|Abbreviation     | Meaning       |
|-----------------|---------------|
| adj             | adjective     |
| adv             | adverb        |
| co              | ???           |
| det             | determiner    |
| mod             | modal         | 
| n               | noun (includes pronouns and proper nouns) |
| part            | participle    |
| prep            | preposition   |
| qn              | quantifier    |
| v               | verb          |


``` {r, echo=FALSE}
table1 <- data.frame(
  "Construction" = c( "no n" ,  "co no" , "mod v n" , "n mod v n" , "n mod v" , "mod v", "n mod", "no qn n" , "no v" , "no n n", "no v n" , "not n",
                      "no n v n" , "not adv" ,"no adv" , "n no" , "no co" , "mod v n n",  "no n v", "no prep n" , "not adj", "n mod v prep" , "n v no" ,  "mod n" ,
                      "n no v n" ,  "not det n" , "not v n" ,  "no det n" ,  "mod v adv" ,  "no n adv" , "n no n" , "n not n"  , "no adj" ,  "no part" ), 
  "Examples" = c("no baby, no horsie, no juice", 
                 "oh no, okay no, yeah no", 
                 "don't touch that, don't fit car, can't open it", 
                 "I don't want juice, I can't find duck, cow won't go Mama", 
                 "I don't know, they don't fit, I can't open", 
                 "don't go, doesn't work, can't catch", 
                 "I can't, Jane doesn't, mine didn't", 
                 "no more stuff, no other pennies, no like doggy", 
                 "no read, no pooped, no want", 
                 "no baby bubble, no this one, no you pencil", 
                 "no sit chair, no have cracker, no eat milk", 
                 "not noodle, not home, not Toffer's", 
                 "no car go car, no comb want brush, no mummy do it", 
                 "not today, not there, not yet", 
                 "no there, no up, no behind", 
                 "mammy no, apple no, train no", 
                 "no no, no yes, no thanks", 
                 "don't eat skin part, don't touch that book, can't find bunny rabit", 
                 "no mail came, no mummy go, no I wanted", 
                 "no in tree, no with this, no like bubbles", 
                 "not good, not dirty, not real", 
                 "I don't want to, Laura don't want to", 
                  "doll sit no, I take no, Joana say no", 
                 "can't tea, don't Mommy, didn't I", 
                  "man no taste it, I no do it", 
                 "not my car, not a cat, not a white", 
                 "not eat rocks, not have coffee, not green one", 
                 "no my turn, no a cow, no the hammer", 
                 "can't come in, don't fall down, doesn't fit here", 
                 "no jacket on, no monkey there, no lie down", 
                 "straws no straws, Mommie no mail, there's no towel", 
                 "pizza not pizza, pizza not apples, that not knees", 
                 "no happy, no pretend, no brown", 
                 "no bouncing, no eating, no hurting")
)

freq <- function(pos) 
{
  filter(undertwo_neg, condensed_p_o_s == pos)$clean_utterances %>% length()
}

table1 <- table1 %>%
  mutate(Frequency = sapply(Construction, freq))

table1 <- table1[order(-table1$Frequency),]

kable(table1[,c(1, 3, 2)]) %>%
  kable_styling(font_size = 12) %>%
  column_spec(4, width = "20em")

table2 <- data.frame("Category" = c("Can", "Want", "Do","Don't", "Don't want", "Don't know", "Don't like", "No _", "No more", "Not _", "Presentential \`No\'", "Pre-VP \`No\'", "Sentence-internal \`No\'", "Presentential \`Not\'", "Pre-VP \`Not\'", "Sentence-internal \'Not\'"), 
                     "Frequency" = c(length(filter(undertwo_neg, can)$clean_utterances), 
                                     length(filter(undertwo_neg, want)$clean_utterances),
                                     length(filter(undertwo_neg, do)$clean_utterances), 
                                     filter(undertwo_neg, grepl('don\'t', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('don\'t want', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('don\'t know', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('don\'t like', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^no [a-z]+$', condensed_p_o_s) & condensed_p_o_s != "no no")$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('( |^)no more( |$)', clean_utterances))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^not [a-z]+$', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^no n v ?.*', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^no v ?.*', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^n no v ?.*', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^not n v ?.*', condensed_p_o_s))$clean_utterances %>% length(),
                                     filter(undertwo_neg, grepl('^not v ?.*', condensed_p_o_s))$clean_utterances %>% length(), 
                                     filter(undertwo_neg, grepl('^n not v ?.*', condensed_p_o_s))$clean_utterances %>% length()), 
                     "Examples" = c("I can't find a blankie, can't eat, no no I can not do", 
                                    "Don't want to, no comb want brush, no want the baby",
                                    "don't like it, I don't feel good, no do it Mummy", 
                                    "don't like it, no don't, I don't know",
                                    "I don't want juice, don't want it, Laura don't want to",
                                    "I don't know, I don't know name of them, you don't know how zip zip up",
                                    "I don't like it, don't like toast, I don't like",
                                    "no go, no stupid, no now, no baby",
                                    "no more, no more corn, there's no more time",
                                    "not bad, not write, not quite",
                                    "no Mommy read, no baby bite me, no you wait there for me", 
                                    "no have black, no give me that, no bite",
                                    "man no taste it, I no eat",
                                    "not Fraser read it, not that keys",
                                    "Not shush, not write this book, not eat rocks",
                                    "cat not mother, that not fit, I not like it too"))

kable(table2, "latex") %>%
  kable_styling(font_size = 12) %>%
  #pack_rows("Don't", 4, 6); makes a header for rows 4-6
  add_indent(c(4, 5, 6, 7)) %>%
  row_spec(3, bold = T) %>%
  column_spec(3, width = "20em")

```


``` {r, include=FALSE}
#filters for 'no [anything], excluding repeated 'no'; 1183 utterances (33.8%)
filter(undertwo_neg, grepl('^no .*', condensed_p_o_s) & !grepl('^(no ?)+$', condensed_p_o_s))$clean_utterances %>% length()

#filters for 'no n [anything]', excluding repeated 'no'; 236 utterances (6.75%)
filter(undertwo_neg, grepl('^no n.*', condensed_p_o_s) & !grepl('^(no ?)+$', condensed_p_o_s))$clean_utterances %>% length()

# filters for 'do not'; 22 utterances (!!!!) vs. 602 'don't' utterances
filter(undertwo_neg, grepl('( |^)do not( |$)', clean_utterances))$clean_utterances
# Same with 'can not'; 2 utterances vs 208 'can't' utterances


```


```{r utterance breakdown, echo=FALSE}

# Bin utterances by month
bin_age <- function(age)
{
  x = floor(age)
  paste(x, x+1, sep = "-")
}

undertwo_neg <- undertwo_neg %>% 
  mutate(bin = bin_age(target_child_age))

# Count frequency of each negation type by utterance
# Right now I'm counting the total number; i might consider just checking if its present in the utterance to eliminate repetitions
negs <- undertwo_neg %>%
  mutate(no = str_count(clean_utterances, '( |^)no( |$)')) %>%
  mutate(not = str_count(clean_utterances, '( |^)not( |$)')) %>%
  mutate(nt = str_count(clean_utterances, '( |^)[a-z]*n\'t( |$)')) %>%
  mutate(sum = no + not + nt) 

negs <- negs[order(negs$bin),]

# Sum negation types by bin
neg_sums <- data.frame("Bin" = unique(negs$bin)) %>%
  # Count the number of times a negative is uttered in each bin
  mutate(Neg_Count = tally(group_by(negs, bin), sum)$n) %>%
  # Calculate the proportion of 'no' utterances followed by each POS in each bin
  mutate(no = tally(group_by(negs, bin), no)$n) %>%
  mutate(not = tally(group_by(negs, bin), not)$n) %>%
  mutate(nt = tally(group_by(negs, bin), nt)$n)

# Calculate proportion of each negation type per instances of negation by bin
neg_proportions <- (neg_sums[,3:5] / neg_sums[,2]) %>%
  mutate(Bin = neg_sums$Bin)
  

# Consolidate data for graphing
neg_sums_melted <- neg_sums%>%subset(select = -Neg_Count) %>%melt(id.vars = "Bin")
neg_proportions_melted <- melt(neg_proportions,id.vars = "Bin")

ggplot(mapping = aes(Bin, value, fill = variable ))+
  geom_bar(data = neg_sums_melted, stat = "identity")+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("Negation Type: All Multi-word Negative Uttera")+
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 70, vjust = 1, hjust=1)) 

ggplot(neg_proportions_melted) +
  geom_bar(stat = "identity", aes(Bin, value, fill = variable ))+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("Negation type: All Multi-word Negative Utterances")+
  scale_fill_brewer(palette="Paired")+
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 70, vjust = 1, hjust=1))


```

```{r no analysis, echo=FALSE}
# No composition

no_tag <- function(pos) 
{
  pos_list = unlist(strsplit(pos, " "))
  
  n_list = grep("^no$", pos_list)
  
  out = pos_list[n_list+1]
  out = out[!is.na(out)]
  return(out)
}

nos <- undertwo_neg %>%
  # Use to filter age range
  #filter(bin %in% unlist(lapply(1:23, bin_age)))%>%
  filter(grepl('(^| )no \\w+', condensed_p_o_s)) %>%
  mutate(no = lapply(condensed_p_o_s, no_tag)) %>%
  # Nonsense words, onomatopoeia, and L2 words
  within(no[grepl("chi|unk|bab|sing|on|uni|wplay|dia|L2|int|fam|neo", no)] <- "other") %>%
  # One row per instance of no; utterances with multiple 'no's are doubled 
  unnest(no) %>%
  filter(!grepl('^$', no))

# Create proportion table
nos_prop <- merge(
  tally(group_by(nos, bin)) %>% dplyr::rename(total = n), 
  dcast(nos, bin~no, value.var = "no", fun.aggregate = length), by = "bin")
# Divide by total to get proportion by bin
nos_prop[,-(1:2)] <- nos_prop[,-(1:2)]/nos_prop[,2]

# Prepare for graphing
nos_prop <- nos_prop[,-2] %>%
  melt(id = "bin", value.name = "proportion", variable.name = "PoS")

# Ensure same order of elements
nos_prop <- nos_prop[order(nos_prop$bin,-nos_prop$proportion),]
ORDER <- unique(nos_prop$PoS)
nos_prop$PoS <- factor(nos_prop$PoS, levels = ORDER)
nos$no <- factor(nos$no, levels = ORDER)

ggplot(nos, aes(bin, fill = no)) +
  geom_bar()+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("\'No\' Composition")+
  theme(axis.text.x = element_text(angle = 70, vjust = 1, hjust=1), plot.title = element_text(hjust = 0.5))+
  theme(legend.key=element_blank(), legend.key.size=unit(12,"point"))+
  labs(fill = "Part of Speech") +
  scale_fill_manual(values=as.vector(alphabet2()))

ggplot(nos_prop, aes(bin, proportion, fill = PoS)) +
  geom_bar(stat ="identity")+
  xlab("Age Bin")+
  ylab("Proportion of Instances")+
  ggtitle("\'No\' Composition")+
  theme(axis.text.x = element_text(angle = 70, vjust = 1, hjust=1), plot.title = element_text(hjust = 0.5))+
  theme(legend.key=element_blank(), legend.key.size=unit(12,"point"))+
  labs(fill = "Part of Speech") +
  scale_fill_manual(values=as.vector(alphabet2()))

# Maybe make one that's just the number of things no combines with per bin

```

```{r Not Composition, echo=FALSE}

not_tag <- function(pos) 
{
  pos_list = unlist(strsplit(pos, " "))
  
  n_list = grep("^not$", pos_list)
  
  out = pos_list[n_list+1]
  out = out[!is.na(out)]
  return(out)
}

nots <- undertwo_neg %>%
  # Use to filter age range
  #filter(bin %in% unlist(lapply(1:23, bin_age)))%>%
  filter(grepl('(^| )not \\w+', condensed_p_o_s)) %>%
  mutate(not = lapply(condensed_p_o_s, not_tag)) %>%
  # notnsense words, onotmatopoeia, and L2 words
  within(not[grepl("chi|unk|bab|sing|on|uni|wplay|dia|L2|int|fam|neo", not)] <- "other") %>%
  # One row per instance of not; utterances with multiple 'not's are doubled 
  unnest(not) %>%
  filter(!grepl('^$', not))

# Create proportion table
nots_prop <- merge(
  tally(group_by(nots, bin)) %>% dplyr::rename(total = n), 
  dcast(nots, bin~not, value.var = "not", fun.aggregate = length), by = "bin")
# Divide by total to get proportion by bin
nots_prop[,-(1:2)] <- nots_prop[,-(1:2)]/nots_prop[,2]

# Prepare for graphing
nots_prop <- nots_prop[,-2] %>%
  melt(id = "bin", value.name = "proportion", variable.name = "PoS")

# Ensure same order of elements
extras <- unique(nots_prop$PoS)[!unique(nots_prop$PoS) %in% ORDER]
not_order <- c(as.character(ORDER), as.character(extras))
nots_prop$PoS <- factor(nots_prop$PoS, levels = not_order)
nots$not <- factor(nots$not, levels = not_order)

ggplot(nots, aes(bin, fill = not)) +
  geom_bar()+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("\'not\' Composition")+
  theme(axis.text.x = element_text(angle = 70, vjust = 1, hjust=1), plot.title = element_text(hjust = 0.5))+
  theme(legend.key=element_blank(), legend.key.size=unit(12,"point"))+
  labs(fill = "Part of Speech") +
  scale_fill_manual(values=as.vector(alphabet2()))

ggplot(nots_prop, aes(bin, proportion, fill = PoS)) +
  geom_bar(stat ="identity")+
  xlab("Age Bin")+
  ylab("Proportion of Instances")+
  ggtitle("\'not\' Composition")+
  theme(axis.text.x = element_text(angle = 70, vjust = 1, hjust=1), plot.title = element_text(hjust = 0.5))+
  theme(legend.key=element_blank(), legend.key.size=unit(12,"point"))+
  labs(fill = "Part of Speech") +
  scale_fill_manual(values=as.vector(alphabet2()))




```

```{r mod Composition, echo=FALSE}

mod_tag <- function(pos) 
{
  pos_list = unlist(strsplit(pos, " "))
  
  n_list = grep("^mod$", pos_list)
  
  out = pos_list[n_list+1]
  out = out[!is.na(out)]
  return(out)
}

mods <- undertwo_neg %>%
  # Use to filter age range
  #filter(bin %in% unlist(lapply(1:23, bin_age)))%>%
  filter(grepl('(^| )mod \\w+', condensed_p_o_s)) %>%
  mutate(mod = lapply(condensed_p_o_s, mod_tag)) %>%
  # modnsense words, omodmatopoeia, and L2 words
  within(mod[grepl("chi|unk|bab|sing|on|uni|wplay|dia|L2|int|fam|neo", mod)] <- "other") %>%
  # One row per instance of mod; utterances with multiple 'mod's are doubled 
  unnest(mod) %>%
  filter(!grepl('^$', mod))

# Create proportion table
mods_prop <- merge(
  tally(group_by(mods, bin)) %>% dplyr::rename(total = n), 
  dcast(mods, bin~mod, value.var = "mod", fun.aggregate = length), by = "bin")
# Divide by total to get proportion by bin
mods_prop[,-(1:2)] <- mods_prop[,-(1:2)]/mods_prop[,2]

# Prepare for graphing
mods_prop <- mods_prop[,-2] %>%
  melt(id = "bin", value.name = "proportion", variable.name = "PoS")

# Ensure same order of elements
extras <- unique(mods_prop$PoS)[!unique(mods_prop$PoS) %in% ORDER]
mod_order <- c(as.character(ORDER), as.character(extras))
mods_prop$PoS <- factor(mods_prop$PoS, levels = mod_order)
mods$mod <- factor(mods$mod, levels = mod_order)

ggplot(mods, aes(bin, fill = mod)) +
  geom_bar()+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("\'mod\' Composition")+
  theme(axis.text.x = element_text(angle = 70, vjust = 1, hjust=1), plot.title = element_text(hjust = 0.5))+
  theme(legend.key=element_blank(), legend.key.size=unit(12,"point"))+
  labs(fill = "Part of Speech") +
  scale_fill_manual(values=as.vector(alphabet2()))

ggplot(mods_prop, aes(bin, proportion, fill = PoS)) +
  geom_bar(stat ="identity")+
  xlab("Age Bin")+
  ylab("Proportion of Instances")+
  ggtitle("\'mod\' Composition")+
  theme(axis.text.x = element_text(angle = 70, vjust = 1, hjust=1), plot.title = element_text(hjust = 0.5))+
  theme(legend.key=element_blank(), legend.key.size=unit(12,"point"))+
  labs(fill = "Part of Speech") +
  scale_fill_manual(values=as.vector(alphabet2()))


```


```{r nt Composition, echo=FALSE}

# Finds successor of n't word; doesn't handle cases where there are multiple
nt_tag <- function(gloss, pos)
{
  gloss_list = strsplit(gloss, " ")
  pos_list <- unlist(strsplit(pos, " "))
  #nt_list = list()
  nt = 0
  for (g in 1:length(gloss_list[[1]])) {
    if (grepl('[a-z]+n\'t', gloss_list[[1]][g])){
      return(pos_list[g+1])
    }
  }
}

nt_tag("hello amn't dog", "co aux n")


nts <- undertwo_neg %>%
  # Use to filter age range
  #filter(bin %in% unlist(lapply(1:23, bin_age)))%>%
  filter(grepl('(^| )[a-z]+n\'t \\w+', clean_utterances)) %>%
  mutate(nt = mapply(nt_tag, clean_utterances, condensed_p_o_s)) %>%
  # ntnsense words, ontmatopoeia, and L2 words
  within(nt[grepl("chi|unk|bab|sing|on|uni|wplay|dia|L2|int|fam|neo", nt)] <- "other") %>%
  # One row per instance of nt; utterances with multiple 'nt's are doubled 
  unnest(nt) %>%
  filter(!grepl('^$', nt))

# Create proportion table
nts_prop <- merge(
  tally(group_by(nts, bin)) %>% dplyr::rename(total = n), 
  dcast(nts, bin~nt, value.var = "nt", fun.aggregate = length), by = "bin")
# Divide by total to get proportion by bin
nts_prop[,-(1:2)] <- nts_prop[,-(1:2)]/nts_prop[,2]

# Prepare for graphing
nts_prop <- nts_prop[,-2] %>%
  melt(id = "bin", value.name = "proportion", variable.name = "PoS")

# Ensure same order of elements
extras <- unique(nts_prop$PoS)[!unique(nts_prop$PoS) %in% ORDER]
nt_order <- c(as.character(ORDER), as.character(extras))
nts_prop$PoS <- factor(nts_prop$PoS, levels = nt_order)
nts$nt <- factor(nts$nt, levels = nt_order)

ggplot(nts, aes(bin, fill = nt)) +
  geom_bar()+
  xlab("Age Bin")+
  ylab("Number of Instances")+
  ggtitle("\'nt\' Composition")+
  theme(axis.text.x = element_text(angle = 70, vjust = 1, hjust=1), plot.title = element_text(hjust = 0.5))+
  theme(legend.key=element_blank(), legend.key.size=unit(12,"point"))+
  labs(fill = "Part of Speech") +
  scale_fill_manual(values=as.vector(alphabet2()))

ggplot(nts_prop, aes(bin, proportion, fill = PoS)) +
  geom_bar(stat ="identity")+
  xlab("Age Bin")+
  ylab("Proportion of Instances")+
  ggtitle("\'nt\' Composition")+
  theme(axis.text.x = element_text(angle = 70, vjust = 1, hjust=1), plot.title = element_text(hjust = 0.5))+
  theme(legend.key=element_blank(), legend.key.size=unit(12,"point"))+
  labs(fill = "Part of Speech") +
  scale_fill_manual(values=as.vector(alphabet2()))

```


```{r Participants, echo=FALSE}
# Participant information

# 173
undertwo_neg$speaker_id %>% unique() %>% length()

speaker_counts <- undertwo_neg %>% count(speaker_id)

# Proportion of total (0, 24) utterances that include negation by age bin (maybe split bar graph?)
#all_utterances
# Proportion of children in each age bin producing negation
# Proportion of utterances that include negation by child (?)
```




PARENTS:

```{r Parents, echo=FALSE}
parent_utterances <- get_utterances(language = "eng", age = age_limits, role_exclude ="Target_Child")
write.csv(parent_utterances, file="raw_data/eng_parent_utterances.csv")


parent_negation <-
 all_utterances %>%
 mutate(clean_utterances = removeWords(gloss, c("xxx ?", "yyy ?", "um ?", "uh ?", "ah ?"))) %>%
 filter(grepl('( |^)no( |$)|( |^)not( |$)|( |^)[a-z]+n\'t( |$)', clean_utterances)) %>%
 filter(!grepl('not yet transcribed need to fix', gloss)) %>%
 filter(!grepl('^ ?$', part_of_speech)) %>%
 mutate(can = grepl('^can | can | can$|cannot|can\'t', clean_utterances)) %>%
  #gotta add did and didn't
 mutate(do = grepl('^do | do | do$|don\'t|does|doesn\'t', clean_utterances)) %>%
 mutate(want = grepl('^want | want | want$', clean_utterances))%>%
 mutate(n_types_clean = unlist(lapply(clean_utterances, count_types))) %>%
 mutate(n_tokens_clean = unlist(lapply(clean_utterances, count_tokens))) %>%
 mutate(type_token_ratio = n_types_clean/n_tokens_clean)


write.csv(english_negation, file="raw_data/eng_negation_undertwo.csv")
```


